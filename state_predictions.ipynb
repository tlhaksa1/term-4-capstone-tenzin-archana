{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be31278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c969b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data \n",
    "dat = pd.read_excel('./maltreatment_data.xlsx')\n",
    "\n",
    "# only retain numbers (not percentages)\n",
    "dat = dat[dat['DataFormat'] == 'Number']\n",
    "\n",
    "# convert cases reported to a numeric value\n",
    "dat['Data'] = pd.to_numeric(dat['Data'], errors='coerce')\n",
    "\n",
    "# drop NA values\n",
    "dat = dat.dropna()\n",
    "\n",
    "# drop  \n",
    "dat = dat[dat['Category'] != 'Other/missing maltreatment type']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c54411a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['United States', 'Alabama', 'Alaska', 'Arizona', 'Arkansas',\n",
       "       'California', 'Colorado', 'Connecticut', 'Delaware',\n",
       "       'District of Columbia', 'Florida', 'Georgia', 'Hawaii', 'Idaho',\n",
       "       'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana',\n",
       "       'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota',\n",
       "       'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n",
       "       'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
       "       'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon',\n",
       "       'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota',\n",
       "       'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
       "       'West Virginia', 'Wisconsin', 'Wyoming', 'Puerto Rico'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['Location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70943f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States\n",
      "Alabama\n",
      "Alaska\n",
      "Arizona\n",
      "Arkansas\n",
      "California\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colorado\n",
      "Connecticut\n",
      "Delaware\n",
      "District of Columbia\n",
      "Florida\n",
      "Skipping state due to single class: Florida\n",
      "Georgia\n",
      "Hawaii\n",
      "Idaho\n",
      "Illinois\n",
      "Indiana\n",
      "Iowa\n",
      "Kansas\n",
      "Kentucky\n",
      "Louisiana\n",
      "Maine\n",
      "Maryland\n",
      "Massachusetts\n",
      "Michigan\n",
      "Minnesota\n",
      "Mississippi\n",
      "Missouri\n",
      "Montana\n",
      "Nebraska\n",
      "Nevada\n",
      "New Hampshire\n",
      "New Jersey\n",
      "Skipping state due to single class: New Jersey\n",
      "New Mexico\n",
      "New York\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "North Carolina\n",
      "North Dakota\n",
      "Ohio\n",
      "Oklahoma\n",
      "Oregon\n",
      "Pennsylvania\n",
      "Rhode Island\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South Carolina\n",
      "South Dakota\n",
      "Tennessee\n",
      "Texas\n",
      "Utah\n",
      "Vermont\n",
      "Virginia\n",
      "Washington\n",
      "West Virginia\n",
      "Wisconsin\n",
      "Wyoming\n",
      "Puerto Rico\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# list of maltreatment types\n",
    "mt_list = dat['Category'].unique()\n",
    "\n",
    "# Build a model for Alabama (test case)\n",
    "all_predictions = pd.DataFrame()\n",
    "\n",
    "for st in dat['Location'].unique():\n",
    "    print(st)\n",
    "    # subset to specific state\n",
    "    state_data = dat[dat['Location'] == st]\n",
    "\n",
    "    # only retain cols required for the model\n",
    "    state_data = state_data[['Category', 'TimeFrame', 'Data']]\n",
    "\n",
    "\n",
    "    # rename columns\n",
    "    state_data = state_data.rename(columns = {'TimeFrame' : 'Year', 'Data' : 'Cases'})\n",
    "\n",
    "    # Pivot the DataFrame to get features for the model\n",
    "    state_features = state_data.pivot_table(index='Year', columns='Category', values='Cases', aggfunc='sum').reset_index()\n",
    "\n",
    "    \n",
    "    \n",
    "    # handling missing values within a maltreatment type \n",
    "    # if there are more than 3 missing values drop the feature \n",
    "    # else impute the values\n",
    "    for mt in state_data['Category'].unique():\n",
    "            na_count = state_features[state_features[mt].isna()].shape[0]\n",
    "            if(na_count>0):\n",
    "                if(na_count <= 3):\n",
    "                    imputer = SimpleImputer(strategy='mean')\n",
    "                    state_features[mt] = imputer.fit_transform(state_features[[mt]])\n",
    "                else:\n",
    "                    state_features.drop(mt, axis=1, inplace=True)\n",
    "                    \n",
    "    # sort to keep in ascending oreder of years\n",
    "    state_features = state_features.sort_values(by='Year')\n",
    "    \n",
    "    # Compute aggregate number of cases based on year\n",
    "    state_out = state_data.groupby('Year')['Cases'].sum().reset_index()\n",
    "\n",
    "    # Create a new column to indicate whether maltreatment cases increased or decreased compared to the previous year\n",
    "    state_out['Increase'] = (state_out['Cases'].diff() > 0).astype(int)\n",
    "\n",
    "    # sort to keep in ascending oreder of years\n",
    "    state_out = state_out.sort_values(by='Year')\n",
    "    \n",
    "    if (state_out['Increase'].unique().size < 2):\n",
    "        print('Skipping state due to single class: '+ st)\n",
    "    \n",
    "    else: \n",
    "    # feature list for the model\n",
    "    # Select features and target variable\n",
    "        feature_list = state_features.columns.to_list()\n",
    "        feature_list.remove('Year') \n",
    "\n",
    "        X = state_features.loc[:, feature_list]\n",
    "        Y = state_out['Increase']\n",
    "\n",
    "        # Initialize and train the logistic regression model\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X, Y)\n",
    "\n",
    "        # Predict the probability of increase or decrease in maltreatment cases for future years\n",
    "        future_years = 5  # Predict for the next 5 years, for example\n",
    "        latest_year_data =state_features.tail(1).loc[:, feature_list]\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(1, future_years + 1):\n",
    "            next_year_data = latest_year_data.copy()\n",
    "            next_year_data += np.random.randint(-10, 10, size=(1, len(feature_list)))  # Adding some random noise to simulate changes over time\n",
    "            prediction = model.predict_proba(next_year_data)\n",
    "            predictions.append({ 'Location' : st, \n",
    "                                'Year': state_features.tail(1)['Year'].iloc[0] + i,\n",
    "                                'Probability_Increase': prediction[0][1],\n",
    "                                'Probability_Decrease': prediction[0][0]})\n",
    "\n",
    "        # Convert predictions to DataFrame\n",
    "        predictions_df = pd.DataFrame(predictions)\n",
    "        all_predictions = pd.concat([all_predictions, predictions_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af14f018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Year</th>\n",
       "      <th>Probability_Increase</th>\n",
       "      <th>Probability_Decrease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.748228e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.644413e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>2025</td>\n",
       "      <td>1.635248e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United States</td>\n",
       "      <td>2026</td>\n",
       "      <td>1.852907e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United States</td>\n",
       "      <td>2027</td>\n",
       "      <td>1.596314e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.143670e-03</td>\n",
       "      <td>0.998856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>2024</td>\n",
       "      <td>2.458089e-03</td>\n",
       "      <td>0.997542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>2025</td>\n",
       "      <td>8.248820e-04</td>\n",
       "      <td>0.999175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>2026</td>\n",
       "      <td>1.366934e-02</td>\n",
       "      <td>0.986331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>2027</td>\n",
       "      <td>2.136699e-03</td>\n",
       "      <td>0.997863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Location  Year  Probability_Increase  Probability_Decrease\n",
       "0   United States  2023          1.748228e-07              1.000000\n",
       "1   United States  2024          1.644413e-07              1.000000\n",
       "2   United States  2025          1.635248e-07              1.000000\n",
       "3   United States  2026          1.852907e-07              1.000000\n",
       "4   United States  2027          1.596314e-07              1.000000\n",
       "..            ...   ...                   ...                   ...\n",
       "0     Puerto Rico  2023          1.143670e-03              0.998856\n",
       "1     Puerto Rico  2024          2.458089e-03              0.997542\n",
       "2     Puerto Rico  2025          8.248820e-04              0.999175\n",
       "3     Puerto Rico  2026          1.366934e-02              0.986331\n",
       "4     Puerto Rico  2027          2.136699e-03              0.997863\n",
       "\n",
       "[255 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b255bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions.to_csv('./state_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e89b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
